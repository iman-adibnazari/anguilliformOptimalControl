{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import pickle\n",
    "import logging\n",
    "import dask.dataframe as dd\n",
    "from sqlalchemy import create_engine\n",
    "from dask.distributed import Client\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from moviepy.editor import VideoClip\n",
    "from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "from dotenv import dotenv_values\n",
    "import hdf5storage\n",
    "import h5py\n",
    "from sys import getsizeof\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname='simDB',\n",
    "        user='user',\n",
    "        password='password',\n",
    "        host='localhost',\n",
    "        port='5432'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def fetch_trial_data(conn, trial_id,n=1,limit=500):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Fetch data for the given trial_id\n",
    "        query = '''\n",
    "        SELECT timestep, simulation_time, input_data, output_data, state_data\n",
    "        FROM simulation_data\n",
    "        WHERE trial_id = %s AND MOD(timestep, %s) = 0\n",
    "        ORDER BY timestep ASC LIMIT %s;\n",
    "        '''\n",
    "        cur.execute(query, (trial_id, n, limit))\n",
    "        rows = cur.fetchall()\n",
    "        \n",
    "        # Deserialize data\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            timestep, simulation_time, input_data_bin, output_data_bin, state_data_bin = row\n",
    "            input_data = np.array(pickle.loads(input_data_bin)).flatten()\n",
    "            output_data = np.array(pickle.loads(output_data_bin)).flatten()\n",
    "            state_data = np.array(pickle.loads(state_data_bin)).flatten()\n",
    "            data.append((timestep, simulation_time, input_data, output_data, state_data))\n",
    "        \n",
    "        cur.close()\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for trial_id {trial_id}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial Parameters  \n",
    "timesteps = 1000\n",
    "trials = 40\n",
    "# Make list of trial ids from 67-108 skipping 78 and 87\n",
    "trial_ids = list(range(67,78)) + list(range(78,87)) + list(range(88,108)) #[67]\n",
    "n = 1 # Downsampling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OutputDim: 40, InputDim: 6, StateDim: 243789\n"
     ]
    }
   ],
   "source": [
    "# Read a single timestep of data from the database to get dimensions of stuff correct\n",
    "conn = get_db_connection()\n",
    "data = fetch_trial_data(conn, trial_ids[0], n, 1)\n",
    "conn.close()\n",
    "timestep, simulation_time, input_data, output_data, state_data = data[0]\n",
    "outputDim = np.size(output_data)\n",
    "inputDim = np.size(input_data)\n",
    "stateDim = np.size(state_data)\n",
    "print(f\"OutputDim: {outputDim}, InputDim: {inputDim}, StateDim: {stateDim}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 GB\n"
     ]
    }
   ],
   "source": [
    "states = np.zeros((stateDim, timesteps, trials))\n",
    "inputs = np.zeros((inputDim, timesteps, trials))\n",
    "outputs = np.zeros((outputDim, timesteps, trials))\n",
    "simulation_times = np.zeros((timesteps, trials))\n",
    "simulation_timesteps = np.zeros((timesteps, trials))\n",
    "print(getsizeof(states)//(1024*1024*1024), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for trial_id 67\n",
      "Fetching data for trial_id 68\n",
      "Fetching data for trial_id 69\n",
      "Fetching data for trial_id 70\n",
      "Fetching data for trial_id 71\n",
      "Fetching data for trial_id 72\n",
      "Fetching data for trial_id 73\n",
      "Fetching data for trial_id 74\n",
      "Fetching data for trial_id 75\n",
      "Fetching data for trial_id 76\n",
      "Fetching data for trial_id 77\n",
      "Fetching data for trial_id 78\n",
      "Fetching data for trial_id 79\n",
      "Fetching data for trial_id 80\n",
      "Fetching data for trial_id 81\n",
      "Fetching data for trial_id 82\n",
      "Fetching data for trial_id 83\n",
      "Fetching data for trial_id 84\n",
      "Fetching data for trial_id 85\n",
      "Fetching data for trial_id 86\n",
      "Fetching data for trial_id 88\n",
      "Fetching data for trial_id 89\n",
      "Fetching data for trial_id 90\n",
      "Fetching data for trial_id 91\n",
      "Fetching data for trial_id 92\n",
      "Fetching data for trial_id 93\n",
      "Fetching data for trial_id 94\n",
      "Fetching data for trial_id 95\n",
      "Fetching data for trial_id 96\n",
      "Fetching data for trial_id 97\n",
      "Fetching data for trial_id 98\n",
      "Fetching data for trial_id 99\n",
      "Fetching data for trial_id 100\n",
      "Fetching data for trial_id 101\n",
      "Fetching data for trial_id 102\n",
      "Fetching data for trial_id 103\n",
      "Fetching data for trial_id 104\n",
      "Fetching data for trial_id 105\n",
      "Fetching data for trial_id 106\n",
      "Fetching data for trial_id 107\n"
     ]
    }
   ],
   "source": [
    "# Iterate over trials and fetch data\n",
    "for i, trial_id in enumerate(trial_ids):\n",
    "\n",
    "    print(f\"Fetching data for trial_id {trial_id}\")\n",
    "    conn = get_db_connection()\n",
    "    trial_data = fetch_trial_data(conn, trial_id,n,limit=timesteps)\n",
    "    conn.close()\n",
    "    \n",
    "    # Extract output data\n",
    "    for timestep, simulation_time, input_data, output_data, state_data in trial_data[:timesteps]:\n",
    "        outputs[:,timestep,i] = output_data\n",
    "        inputs[:,timestep,i] = input_data\n",
    "        states[:,timestep,i] = state_data\n",
    "        simulation_times[timestep,i] = simulation_time\n",
    "        simulation_timesteps[timestep,i] = timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.48000000e+02 -5.21609373e-05  4.99955557e+01 ... -4.09833327e+02\n",
      " -1.70334065e+01 -1.78415533e+01]\n"
     ]
    }
   ],
   "source": [
    "# Check whats in the state matrix\n",
    "print(states[:,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfileNamehdf5 = config[\"currentDirectory\"] +\"data/archivedDataSets/ContiguousAssembly/FreqSweepDataset.hdf5\"\n",
    "with h5py.File(outfileNamehdf5, 'w') as f:\n",
    "    f.create_dataset('stateData', data=states,maxshape=(None,None,None),chunks=(4096,4096,1))\n",
    "    f.create_dataset('inputData', data=inputs,maxshape=(None,None,None),chunks=(4096,4096,1))\n",
    "    f.create_dataset('outputData', data=outputs,maxshape=(None,None,None),chunks=(4096,4096,1))\n",
    "    f.create_dataset('simulationTimes', data=simulation_times,maxshape=(None,None),chunks=(4096,1))\n",
    "    f.create_dataset('simulationTimesteps', data=simulation_timesteps,maxshape=(None,None),chunks=(4096,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
